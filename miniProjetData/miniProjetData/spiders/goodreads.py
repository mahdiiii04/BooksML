import scrapy

REVIWERS = ['1-otis-chandler',
 '2-odawg-diggity',
 '3-adrian',
 '5-elizabeth',
 '6-kelly',
 '7-sundeep',
 '8-evan-pon',
 '9-darius',
 '10-florence-chandler',
 '12-randy',
 '13-michael',
 '15-jonathan-kart',
 '16-keaka',
 '18-graham',
 '20-mike-jones',
 '21-zack',
 '22-martin',
 '23-daphne-chandler',
 '24-harry-chandler',
 '25-spencer',
 '26-douglas',
 '27-jimmy',
 '28-patrick',
 '29-eric',
 '31-sarah',
 '33-nellie',
 '34-greg-veen',
 '35-michael-siliski',
 '37-tin',
 '38-matt',
 '40-basil',
 '43-vinil',
 '44-julie',
 '45-maureen',
 '47-kathy',
 '49-tim',
 '50-melanie',
 '52-bryce',
 '53-ali',
 '55-dpon',
 '56-jeff',
 '57-andrew',
 '58-kelly',
 '59-jason',
 '61-wooj',
 '62-shannon',
 '63-amanda-mandy',
 '64-brent',
 '65-kimball',
 '66-sean',
 '68-lauren',
 '69-diana',
 '70-susan',
 '71-amy-wilkinson',
 '72-stephen',
 '73-michael-economy',
 '74-robert',
 '76-jayson',
 '78-hadley',
 '84-brandon',
 '86-matt',
 '87-monica',
 '88-cynthia-zavalza-siedel',
 '89-jennifer',
 '90-butrus',
 '91-may',
 '92-forest',
 '93-leila',
 '94-may',
 '95-kirk',
 '96-ray',
 '97-ross-venook',
 '99-ryan',
 '101-joel',
 '103-alexandra',
 '104-daniel',
 '105-deepti',
 '106-andrew',
 '107-jessica',
 '108-myriam',
 '109-jenni',
 '110-trixie-kennedy',
 '113-tom',
 '114-claire',
 '116-jim',
 '117-jonathan',
 '118-gaby',
 '119-bettina-chandler',
 '121-dwezil-bouche',
 '122-beatrice-badro',
 '123-alex',
 '124-matt',
 '126-alex',
 '127-daniel-herrera',
 '128-daniel-klein',
 '129-jen',
 '131-linh',
 '132-shelly',
 '134-christy',
 '136-xochi-birch',
 '137-nick',
 '138-kaylie',
 '139-linda',
 '140-leilah-bernstein',
 '141-sarah',
 '143-maciek',
 '144-xinghua',
 '145-brian',
 '146-andy',
 '147-mike',
 '148-cindy',
 '149-beatrice',
 '150-kari',
 '151-susan',
 '153-ann',
 '155-lila',
 '156-tracey',
 '157-marian',
 '158-willis',
 '159-steve',
 '160-liz',
 '161-seth-williams',
 '163-david',
 '165-stacey',
 '166-leslie',
 '167-kim',
 '168-valerie',
 '169-ginny',
 '170-brandi',
 '171-lyron-bennett',
 '172-larinda',
 '175-reuben',
 '177-jo',
 '178-emily',
 '179-mike',
 '180-adam',
 '181-adjoa',
 '182-doug',
 '183-kay',
 '184-tara',
 '185-bex',
 '186-kim',
 '187-carol',
 '188-sue',
 '190-brandee',
 '191-darice',
 '192-david-allen',
 '193-melissa',
 '194-erin',
 '195-dan',
 '196-cynthia',
 '197-benjamin-jacobsen',
 '198-maisie',
 '202-meetali',
 '203-tomasz',
 '204-chris',
 '205-allyson',
 '206-dan-nevarez',
 '207-shannon',
 '208-shannon',
 '209-rebecca',
 '210-deb',
 '213-kerry',
 '214-yeva',
 '215-heather',
 '216-steve-sarner',
 '217-marilyn-deyoung',
 '218-mike',
 '219-ashley',
 '222-puneet',
 '223-warren',
 '224-simrin',
 '225-jade',
 '228-lisa',
 '230-stan',
 '231-msing',
 '234-ryan',
 '235-dan',
 '236-serena',
 '237-gretchen',
 '238-nora',
 '239-ryan-bartelmay',
 '241-bil',
 '242-julia',
 '243-corinne',
 '244-erin',
 '245-helena',
 '247-poopypants',
 '248-kathleen',
 '249-karolanne',
 '250-mythili',
 '251-meera',
 '252-shaunak',
 '253-shubha',
 '255-liza',
 '257-tesfa',
 '259-alvar',
 '260-anne',
 '262-jamie',
 '263-leah']

class GoodreadsSpider(scrapy.Spider):
    name = "goodreads"
    allowed_domains = ["goodreads.com"]

    def start_requests(self):
            for reviewer in REVIWERS:
                for page in range(1, 21):
                    url = f"https://www.goodreads.com/review/list/{reviewer}?order=d&page={page}&sort=review&view=reviews"
                    yield scrapy.Request(url=url, callback=self.parse)        

    def parse(self, response):
        rows = response.css('tr.bookalike.review')
        for row in rows:
            book_link = 'https://www.goodreads.com' + row.css('td.field.title a::attr(href)').get()
            book_title = row.css('td.field.title a::text').get()
            book_author = row.css('td.field.author a::text').get()
            book_rating = row.css('td.field.rating span::attr(title)').get()
            user_id = response.url.split('list/')[1].split('?order')[0]

            request = scrapy.Request(book_link, callback=self.book_parser)
            request.meta['title'] = book_title.strip()
            request.meta['author'] = book_author.strip()
            request.meta['rating'] = book_rating
            request.meta['user_id'] = user_id
            yield request

    def book_parser(self, response):
        genres = [genre.split('genres/')[1] for genre in response.css('a.Button.Button--tag.Button--medium::attr(href)').getall()[:7]]        
        image = response.css('img.ResponsiveImage::attr(src)').get()
        year = response.css('[data-testid="publicationInfo"]::text').get().split(', ')[1]
        title = response.meta['title']
        author = response.meta['author']
        rating = response.meta['rating']
        user_id = response.meta['user_id']

        yield {
            'user_id' : user_id,
            'title' : title,
            'author' : author,
            'rating' : rating,
            'image' : image,
            'year' : year,
            'genres' : genres           
        }


